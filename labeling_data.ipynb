{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  landuse  database                   geometry\n",
      "0  formal      1984  POINT (36.81875 -1.28296)\n",
      "1  formal      1984  POINT (36.82147 -1.28555)\n",
      "2  formal      1984  POINT (36.82169 -1.28429)\n",
      "3  formal      1984  POINT (36.82322 -1.28458)\n",
      "4  formal      1984  POINT (36.81933 -1.28491)\n",
      "landuse\n",
      "formal        900\n",
      "informal      900\n",
      "vegetation    900\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load shapefiles\n",
    "formal_gdf = gpd.read_file(\"landuse_class/formal.shp\")\n",
    "informal_gdf = gpd.read_file(\"landuse_class/informal.shp\")\n",
    "vegetation_gdf = gpd.read_file(\"landuse_class/vegetation.shp\")\n",
    "\n",
    "# Drop 'Id' columns in formal and vegetation\n",
    "formal_gdf = formal_gdf.drop(columns=[\"Id\"], errors='ignore')\n",
    "vegetation_gdf = vegetation_gdf.drop(columns=[\"Id\"], errors='ignore')\n",
    "\n",
    "# Combine all into a single GeoDataFrame\n",
    "combined_gdf = pd.concat([formal_gdf, informal_gdf, vegetation_gdf], ignore_index=True)\n",
    "\n",
    "# Check the result (total of 900 points per lu class)\n",
    "print(combined_gdf.head())\n",
    "print(combined_gdf[\"landuse\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# Check Projection\n",
    "print(combined_gdf.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Landsat TIF files\n",
    "Load the images through public API from Dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded landsat_1984.tif to landsat_images/landsat_1984.tif\n",
      "Downloaded landsat_2009.tif to landsat_images/landsat_2009.tif\n",
      "Downloaded landsat_2019.tif to landsat_images/landsat_2019.tif\n"
     ]
    }
   ],
   "source": [
    "# Create new output folder \n",
    "output_dir = \"landsat_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Download multiple files\n",
    "landsat_files = {\n",
    "    \"1984\": \"https://www.dropbox.com/scl/fi/nk6xavounp62ua13knj8z/nairobi_landsat_1984_allbands.tif?rlkey=1hy39oiei4fwcsahydg007n6s&st=smighyej&dl=1\",\n",
    "    \"2009\": \"https://www.dropbox.com/scl/fi/flagfp77yvcyxt0b7plyj/nairobi_landsat_2009_allbands.tif?rlkey=etoqn6whwlkkz08cis68oyp6q&st=gpi4nlk5&dl=1\",\n",
    "    \"2019\": \"https://www.dropbox.com/scl/fi/l09necnzqgyigbd13iddp/nairobi_landsat_2019_allbands.tif?rlkey=0gec6urstoqomk6141f2ag5re&st=4h1715d2&dl=1\"\n",
    "}\n",
    "\n",
    "for year, url in landsat_files.items():\n",
    "    output_path = os.path.join(output_dir, f\"landsat_{year}.tif\")\n",
    "    r = requests.get(url)\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(f\"Downloaded landsat_{year}.tif to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import mapping\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# Check Projection\n",
    "landsat_1984 = \"landsat_images/landsat_1984.tif\"\n",
    "\n",
    "# Open the image and print its CRS\n",
    "with rasterio.open(landsat_1984) as src:\n",
    "    print(\"CRS:\", src.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Data by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Geodataframes with the labeled data by year\n",
    "gdf_1984 = combined_gdf[combined_gdf['database'] == 1984]\n",
    "gdf_2009 = combined_gdf[combined_gdf['database'] == 2009]\n",
    "gdf_2019 = combined_gdf[combined_gdf['database'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier function\n",
    "\n",
    "def classify_year(year, gdf, tif_path, out_path):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    # Open raster\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        image = src.read()  # (bands, rows, cols)\n",
    "        transform = src.transform\n",
    "        raster_crs = src.crs\n",
    "        raster_bounds = src.bounds\n",
    "        meta = src.meta.copy()\n",
    "        _, n_rows, n_cols = image.shape\n",
    "\n",
    "    # Reproject training points to match raster\n",
    "    if gdf.crs != raster_crs:\n",
    "        gdf = gdf.to_crs(raster_crs)\n",
    "\n",
    "    # Filter training points to those within raster extent\n",
    "    raster_geom = box(*raster_bounds)\n",
    "    gdf = gdf[gdf.geometry.within(raster_geom)]\n",
    "    print(f\"[{year}] Points after spatial filter: {len(gdf)}\")\n",
    "\n",
    "    if len(gdf) == 0:\n",
    "        raise ValueError(f\"No valid training points within raster bounds for year {year}.\")\n",
    "\n",
    "    # Extract coordinates and labels\n",
    "    coords = [(geom.x, geom.y) for geom in gdf.geometry]\n",
    "    labels = gdf['landuse'].astype('category').cat.codes.values\n",
    "\n",
    "    # Convert coordinates to row/col pixel positions\n",
    "    rows_cols = [~transform * (x, y) for x, y in coords]\n",
    "    rows, cols = zip(*rows_cols)\n",
    "    rows = np.array(rows)\n",
    "    cols = np.array(cols)\n",
    "\n",
    "    # Filter NaNs\n",
    "    valid = (~np.isnan(rows)) & (~np.isnan(cols))\n",
    "    rows = rows[valid].astype(int)\n",
    "    cols = cols[valid].astype(int)\n",
    "    labels = labels[valid]\n",
    "\n",
    "    # Filter to points within raster dimensions\n",
    "    in_bounds = (rows >= 0) & (rows < n_rows) & (cols >= 0) & (cols < n_cols)\n",
    "    rows = rows[in_bounds]\n",
    "    cols = cols[in_bounds]\n",
    "    labels = labels[in_bounds]\n",
    "\n",
    "    print(f\"[{year}] Training samples used: {len(labels)}\")\n",
    "\n",
    "    # Extract pixel values for training\n",
    "    samples = image[:, rows, cols].T  # shape: (samples, bands)\n",
    "\n",
    "    # Train Random Forest model\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(samples, labels)\n",
    "\n",
    "    # Classify entire raster\n",
    "    reshaped_img = image.reshape(image.shape[0], -1).T\n",
    "    predictions = clf.predict(reshaped_img)\n",
    "    classified = predictions.reshape((n_rows, n_cols))\n",
    "\n",
    "    # Save output raster\n",
    "    meta.update({\"count\": 1, \"dtype\": 'int16'})\n",
    "    with rasterio.open(out_path, \"w\", **meta) as dest:\n",
    "        dest.write(classified.astype('int16'), 1)\n",
    "\n",
    "    print(f\"[{year}] Classification complete. Saved to {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1984] Points after spatial filter: 899\n",
      "[1984] Training samples used: 899\n",
      "[1984] Classification complete. Saved to classified_outputs/classified_1984.tif\n",
      "[2009] Points after spatial filter: 900\n",
      "[2009] Training samples used: 900\n",
      "[2009] Classification complete. Saved to classified_outputs/classified_2009.tif\n",
      "[2019] Points after spatial filter: 900\n",
      "[2019] Training samples used: 880\n",
      "[2019] Classification complete. Saved to classified_outputs/classified_2019.tif\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if not exists\n",
    "os.makedirs(\"classified_outputs\", exist_ok=True)\n",
    "\n",
    "# Run Classifier \n",
    "classify_year(\n",
    "    year='1984',\n",
    "    gdf=gdf_1984,\n",
    "    tif_path='landsat_images/landsat_1984.tif',\n",
    "    out_path='classified_outputs/classified_1984.tif'\n",
    ")\n",
    "\n",
    "classify_year(\n",
    "    year='2009',\n",
    "    gdf=gdf_2009,\n",
    "    tif_path='landsat_images/landsat_2009.tif',\n",
    "    out_path='classified_outputs/classified_2009.tif'\n",
    ")\n",
    "\n",
    "classify_year(\n",
    "    year='2019',\n",
    "    gdf=gdf_2019,\n",
    "    tif_path='landsat_images/landsat_2019.tif',\n",
    "    out_path='classified_outputs/classified_2019.tif'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musa-650",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
